{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'llama' # else 'gpt'\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from glob import glob\n",
    "import json\n",
    "from num2words import num2words\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE HOW THE ANSEWR IS PICKED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama = ChatOllama(\n",
    "        model=\"llama3.2\",\n",
    "        temperature=0,\n",
    "        num_ctx=4096,\n",
    "        num_predict=2048,\n",
    "        verbose=True\n",
    "    )\n",
    "model = None\n",
    "if model_name == 'llama':\n",
    "    model = llama\n",
    "else:\n",
    "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "        # base_url=\"...\",\n",
    "        # organization=\"...\",\n",
    "        # other params...\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('./selected_questions/*.jsonl')\n",
    "questions = []\n",
    "for path in files:\n",
    "    question_type = path[path.rfind('/')+1:-6]\n",
    "    with open(path, 'r') as file:\n",
    "        for i in range(100):\n",
    "            line = file.readline()\n",
    "            question = json.loads(line)\n",
    "            question['type'] = question_type\n",
    "            questions.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_last_select_statement(query: str) -> str:\n",
    "    # Remove the WITH clause and keep only the last SELECT statement\n",
    "    query = re.sub(r'WITH\\s+.*?\\)\\s*', '', query, flags=re.IGNORECASE | re.DOTALL)\n",
    "    select_statements = re.findall(r'(SELECT\\s+.*?FROM\\s+.*?)(?=\\s+WHERE|\\s+GROUP BY|\\s+ORDER BY|$)', query, re.IGNORECASE | re.DOTALL)\n",
    "    return select_statements[-1].strip() if select_statements else \"\"\n",
    "\n",
    "def extract_with_table_names(query: str) -> list:\n",
    "    # Extract all table names defined in the WITH clause\n",
    "    with_tables = re.findall(r'\\b(\\w+)\\b\\s+AS\\s*\\(', query, re.IGNORECASE)\n",
    "    return with_tables\n",
    "\n",
    "def extract_predicates(query: str, with_tables: list) -> str:\n",
    "    # Find the last occurrence of WHERE and extract predicates after it\n",
    "    where_matches = list(re.finditer(r'WHERE\\s+', query, re.IGNORECASE))\n",
    "    if not where_matches:\n",
    "        return \"\"\n",
    "    last_where = where_matches[-1].end()\n",
    "    predicates_section = query[last_where:].strip()\n",
    "    predicates_section = re.split(r'GROUP BY|ORDER BY', predicates_section, maxsplit=1, flags=re.IGNORECASE)[0].strip()\n",
    "    \n",
    "    # Split predicates by AND/OR while keeping the delimiters\n",
    "    predicate_parts = re.split(r'\\s+(AND|OR)\\s+', predicates_section, flags=re.IGNORECASE)\n",
    "    \n",
    "    # List of spatial functions to remove\n",
    "    spatial_functions = [\n",
    "        'ST_Intersects', 'ST_Contains', 'ST_DWithin', 'ST_Touches', 'ST_Overlaps',\n",
    "        'ST_Crosses', 'ST_Equals', 'ST_Disjoint', 'ST_Within'\n",
    "    ]\n",
    "    \n",
    "    # Keep only non-spatial predicates and those not referring to WITH tables\n",
    "    filtered_predicates = []\n",
    "    i = 0\n",
    "    while i < len(predicate_parts):\n",
    "        predicate = predicate_parts[i].strip()\n",
    "        if not any(func in predicate for func in spatial_functions) and not any(tbl in predicate for tbl in with_tables):\n",
    "            filtered_predicates.append(predicate)\n",
    "        if i + 1 < len(predicate_parts):\n",
    "            filtered_predicates.append(predicate_parts[i + 1])  # Keep AND/OR operators\n",
    "        i += 2\n",
    "    \n",
    "    return \" \".join(filtered_predicates).strip()\n",
    "\n",
    "def rebuild_query(original_query: str, q_type: str) -> str:\n",
    "    with_tables = extract_with_table_names(original_query)\n",
    "    select_statement = extract_last_select_statement(original_query)\n",
    "    non_spatial_predicates = extract_predicates(original_query, with_tables)\n",
    "    if 'loc' in q_type:\n",
    "        non_spatial_predicates += ' AND addr_city IS NOT Null'\n",
    "    # Extract the table names from the FROM clause\n",
    "    from_match = re.search(r'FROM\\s+(.*?)(WHERE|GROUP BY|ORDER BY|$)', select_statement, re.IGNORECASE | re.DOTALL)\n",
    "    if from_match:\n",
    "        tables = [tbl.strip() for tbl in from_match.group(1).split(',')]\n",
    "        remaining_tables = [tbl for tbl in tables if tbl not in with_tables]\n",
    "        if remaining_tables:\n",
    "            select_statement = re.sub(r'FROM\\s+.*?(WHERE|GROUP BY|ORDER BY|$)', f'FROM {remaining_tables[0]} \\1', select_statement, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Clean up any remaining commas in FROM clause\n",
    "    # select_statement = re.sub(r',\\s*', ' ', select_statement)\n",
    "    \n",
    "    new_query = select_statement.strip()\n",
    "    if non_spatial_predicates:\n",
    "        new_query += f\" WHERE {non_spatial_predicates}\"\n",
    "    \n",
    "    new_query += \" ORDER BY RANDOM() LIMIT 1\"\n",
    "    return new_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angle_description': 'southeast', 'angle': 151.82904794657867}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_angle():\n",
    "    direction_filters = [\n",
    "        ['north', random.choice([random.uniform(0.0,22.5), random.uniform(337.5,360)])],\n",
    "        ['northeast', random.uniform(22.5, 67.5)],\n",
    "        ['east', random.uniform(67.5, 112.5)],\n",
    "        ['southeast', random.uniform(112.5, 157.5)],\n",
    "        ['south', random.uniform(157.5, 202.5)],\n",
    "        ['southwest', random.uniform(202.5, 247.5)],\n",
    "        ['west', random.uniform(247.5, 292.5)],\n",
    "        ['northwest', random.uniform(292.5, 337.5)]\n",
    "    ]\n",
    "\n",
    "    d = random.choice(range(len(direction_filters)))    \n",
    "    # Select a random value from the combined list\n",
    "    # random_angle_in_direction = int(random.choice(direction_filters[d][1]))\n",
    "    return {'angle_description': direction_filters[d][0], 'angle': direction_filters[d][1]}\n",
    "random_angle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt2 = str(\"Given a question and a text answer, parse the text answer to json format.\"\n",
    "                     \" The location must be provided as a complete address,\"\n",
    "                     \" any measurment must be in metric units,\"\n",
    "                     \" and directions must be converted to azimuth angle in degress.\"\n",
    "                     \" Try to match the following schema:\"\n",
    "                     \"\"\"\n",
    "                        {\n",
    "                            \"name\" string\n",
    "                            \"address\": string,\n",
    "                            \"count\": integer,\n",
    "                            \"distance\": integer,\n",
    "                            \"length\": integer,\n",
    "                            \"area\": integer,\n",
    "                            \"azimuth_angle\": integer,\n",
    "                            %OTHER_ATT%\n",
    "                        }\n",
    "                    If a value is missing don't include it in the output, and don't write any comments.\n",
    "                    All json blocks must be enclosed with ```json and ```\n",
    "                     \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from psycopg.rows import dict_row\n",
    "\n",
    "def run_sql(sql, conn, timeout):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SET statement_timeout = %d\" % timeout)\n",
    "    try:\n",
    "        cur.execute(sql)\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        return {'output': [], 'error': str(e)}\n",
    "    records = cur.fetchmany(size=100)\n",
    "    cur.close()\n",
    "    return {'output': [{k: row[k] for k in row if row[k] is not None} for row in records], 'error': ''}\n",
    "conn = psycopg.connect(\n",
    "    host = 'localhost',\n",
    "    dbname = 'osm_ca',\n",
    "    user = 'postgres',\n",
    "    password = 'postgres',\n",
    "    port = 5432,\n",
    "    row_factory=dict_row,\n",
    "    # options=\"-c statement_timeout=180000\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function was generated with ChatGPT to get random answers for the multihop quesitons for the random baseline\n",
    "\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "\n",
    "def get_random_value(attribute: str):\n",
    "    attribute_generators = {\n",
    "        \"Architect\": fake.name,\n",
    "        \"Built\": lambda: random.randint(1800, 2025),\n",
    "        \"Created\": lambda: fake.date(),\n",
    "        \"Established\": lambda: random.randint(1700, 2025),\n",
    "        \"Director\": fake.name,\n",
    "        \"Founder\": fake.name,\n",
    "        \"Headquarters\": fake.city,\n",
    "        \"Opened\": lambda: random.randint(1800, 2025),\n",
    "        \"Opening date\": fake.date,\n",
    "        \"Affiliated university\": lambda: f\"{fake.company()} University\",\n",
    "        \"Emergency department\": lambda: random.choice([\"Yes\", \"No\"]),\n",
    "        \"Helipad\": lambda: random.choice([\"Yes\", \"No\"]),\n",
    "        \"Date opened\": fake.date,\n",
    "        \"Volume of largest tank\": lambda: f\"{random.randint(1000, 100000)} liters\",\n",
    "        \"Capacity\": lambda: random.randint(50, 100000),\n",
    "        \"Former names\": lambda: fake.company(),\n",
    "        \"Motto\": fake.sentence,\n",
    "        \"Mascot\": lambda: fake.word().capitalize(),\n",
    "        \"Nickname\": lambda: fake.word().capitalize(),\n",
    "        \"Designed by\": fake.name,\n",
    "        \"Nearest\\xa0city\": fake.city\n",
    "    }\n",
    "    generator = attribute_generators.get(attribute)\n",
    "    if generator:\n",
    "        return generator()\n",
    "    else:\n",
    "        return \"Attribute not recognized\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/majid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/majid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 2800/2800 [04:55<00:00,  9.47it/s] \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import importlib\n",
    "import evaluate\n",
    "importlib.reload(evaluate)\n",
    "from tqdm import tqdm\n",
    "\n",
    "q_types = set([q['type'] for q in questions])\n",
    "q_answers = {t: [{'answers': q['answers'], 'id': q['id']} for q in questions if q['type'] == t] for t in q_types}\n",
    "# modify it to query and select a random answer using sql\n",
    "answers = []\n",
    "for q in tqdm(questions):\n",
    "    element = []\n",
    "    if 'name' in q['type'] or 'loc' in q['type']:\n",
    "        sql = rebuild_query(q['sql'], q['type'])\n",
    "        element = run_sql(sql.replace('\\x01', ''), conn, 1000)['output']\n",
    "    elif 'angle' in q['type']:\n",
    "        element = [random_angle()]\n",
    "    elif 'area' in q['type']:\n",
    "        element = [{'area': random.randint(1,10**10)}]\n",
    "    elif 'length' in q['type']:\n",
    "        element = [{'length': random.randint(1,10**10)}]\n",
    "    elif 'distance' in q['type']:\n",
    "        element = [{'distance': random.randint(1,10**10)}]\n",
    "    elif 'count' in q['type']:\n",
    "        element = [{'count': random.randint(1,10**10)}]\n",
    "    elif 'multihop1' in q['type']:\n",
    "        att = q['answers'][0]['multihop_attribute']\n",
    "        element = [{'multihop_long_answer': att + ' ' + str(get_random_value(att))}]\n",
    "    key = ''\n",
    "    if 'multihop1' in q['type']:\n",
    "        key = 'multihop_long_answer'\n",
    "    elif 'name' in q['type']:\n",
    "        key = 'name'\n",
    "    elif 'loc' in q['type']:\n",
    "        key = 'address'\n",
    "    elif 'angle' in q['type']:\n",
    "        key = 'angle_description'\n",
    "    elif 'area' in q['type']:\n",
    "        key = 'area'\n",
    "    elif 'length' in q['type']:\n",
    "        key = 'length'\n",
    "    elif 'count' in q['type']:\n",
    "        key = 'count'\n",
    "    elif 'distance' in q['type']:\n",
    "        key = 'distance'\n",
    "    true_answer = []\n",
    "    for a in element:\n",
    "        v = evaluate.get_osm_value(a, key)\n",
    "        if v == None:\n",
    "            continue\n",
    "        if key in ['area', 'length', 'count', 'distance']:\n",
    "            v = num2words(v)\n",
    "        if 'area' == key:\n",
    "            v += ' meters squared'\n",
    "        elif key in ['length', 'distance']:\n",
    "            v += ' meters'\n",
    "        true_answer.append(v)\n",
    "    _true_answer = '\\n'\n",
    "    i = 0\n",
    "    for t in true_answer:\n",
    "        _true_answer += '\\n' + t\n",
    "        i+=1\n",
    "        if len(_true_answer) > 256 or i >= 10:\n",
    "            break\n",
    "    _true_answer = _true_answer[1:]\n",
    "    answers.append({'id': q['id'], 'content': _true_answer})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'AIMessage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m answered \u001b[38;5;241m=\u001b[39m {q[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]: q \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m json_answers}\n",
      "\u001b[0;31mTypeError\u001b[0m: 'AIMessage' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "answered = {q['id']: q for q in json_answers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800/2800 [1:01:37<00:00,  1.32s/it]  \n"
     ]
    }
   ],
   "source": [
    "json_answers = []\n",
    "\n",
    "for i in tqdm(range(len(questions))):\n",
    "    q = questions[i]\n",
    "    if 'multihop1' in q['type']:\n",
    "        sys_prompt= system_prompt2.replace('%OTHER_ATT%', '\"%s\": string' % q['answers'][0]['multihop_attribute'])\n",
    "    else:\n",
    "        sys_prompt= system_prompt2.replace('%OTHER_ATT%', '')\n",
    "    a = answers[i]\n",
    "    if a['id'] != q['id']:\n",
    "        for j in range(len(answers)):\n",
    "            if answers[j]['id'] == q['id']:\n",
    "                a = answers[j]\n",
    "                break\n",
    "    messages = [\n",
    "            SystemMessage(content=sys_prompt),\n",
    "            HumanMessage(content=\"Question: %s\\nAnswer: %s\" % (q['question'], a['content']))\n",
    "        ]\n",
    "    json_answers.append({'content': llama.invoke(messages).content, 'id': q['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./json_answers_shuffled.json', 'w') as file:\n",
    "#         file.write(json.dumps(json_answers, indent=2))\n",
    "        # file.write(json.dumps([{'content': json_answers[i].content, 'id': questions[i]['id']} for i in range(len(questions))], indent=2))\n",
    "with open('./json_answers_shuffled.json', 'r') as file:\n",
    "        json_answers = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def flatten_if_nested(array):\n",
    "    # Check if the input is a list and contains nested lists\n",
    "    if isinstance(array, list) and any(isinstance(item, list) for item in array):\n",
    "        flattened = []\n",
    "        for item in array:\n",
    "            if isinstance(item, list):\n",
    "                flattened.extend(flatten_if_nested(item))\n",
    "            else:\n",
    "                flattened.append(item)\n",
    "        return flattened\n",
    "    else:\n",
    "        return array  # Return the input as-is if it's not a list or doesn't contain nested lists\n",
    "\n",
    "def extract_json_blocks(text, i):\n",
    "    # Regular expression pattern to match JSON blocks\n",
    "    pattern = r'```[\\s]*json(.*?)```'\n",
    "    pattern1 = r'\\b\\d+(?:_\\d+)*\\b'\n",
    "    pattern2 = r'\\b\\d+(?:,\\d+)*\\b'\n",
    "    pattern3 = r'//.*?\\n'\n",
    "    pattern4 = r',\\s*}'\n",
    "    pattern5 = r'}\\s*{'\n",
    "    # Find all JSON blocks\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    # Parse each match to ensure valid JSON\n",
    "    json_blocks = []\n",
    "    for match in matches:\n",
    "        try:\n",
    "            # Remove any leading/trailing whitespace and parse as JSON\n",
    "            s = match.strip()\n",
    "            s = re.sub(pattern1, lambda x: x.group().replace('_', ''), s)\n",
    "            s = re.sub(pattern2, lambda x: x.group().replace(',', ''), s)\n",
    "            s = re.sub(pattern3, '', s)\n",
    "            s = re.sub(pattern4, '}', s)\n",
    "            s = s.replace('''\\\\\\'''', '''\\'''').replace('''\\\\&''', '''&''').replace(': integer', ': null').replace(' * ', '')\n",
    "            # Case 1: Replace any number followed by '+' with just the first number\n",
    "            s = re.sub(r'(\\d[\\d\\s]*)(?:\\s*\\+\\s*[\\d\\s\\+]+)', lambda m: m.group(1).replace(' ', ''), s)\n",
    "            # Case 2: Remove spaces within standalone numbers\n",
    "            s = re.sub(r'\\b\\d[\\d\\s]*\\b', lambda m: m.group(0).replace(' ', ''), s)\n",
    "            if re.search(pattern5, s):\n",
    "                s = re.sub(pattern5, '},\\n{', s)\n",
    "                s = '[\\n%s\\n]' % s\n",
    "            convert_area = False\n",
    "            if 'acres' in s:\n",
    "                convert_area = True\n",
    "                s = s.replace(' acres,', ',')\n",
    "                s = s.replace('acres,', ',')\n",
    "            json_data = json.loads(s)\n",
    "            if convert_area and 'area' in json_data:\n",
    "                json_data['area'] = json_data['area'] * 4046.8564224\n",
    "            json_blocks.append(json_data)\n",
    "        except json.JSONDecodeError as w:\n",
    "            print(w)\n",
    "            # If parsing fails, print an error message (can log or handle as needed)\n",
    "            print(i)\n",
    "            print(s)\n",
    "            print(\"Warning: Found an invalid JSON block.\") \n",
    "    return flatten_if_nested(json_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_answers = []\n",
    "for q in questions:\n",
    "    a = json_answers[i]\n",
    "    if a['id'] != q['id']:\n",
    "        for j in range(len(json_answers)):\n",
    "            if json_answers[j]['id'] == q['id']:\n",
    "                a = json_answers[j]\n",
    "                break\n",
    "    parsed_answers.append(extract_json_blocks(a['content'], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from pyproj import Geod\n",
    "\n",
    "geod = Geod(ellps='WGS84')\n",
    "geocoder = Nominatim(user_agent=\"Geocoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/majid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/majid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/majid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/majid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import evaluate\n",
    "importlib.reload(evaluate)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_evaluation = []\n",
    "\n",
    "# evaluate text answers\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    q = questions[i]\n",
    "    a = answers[i]\n",
    "    if a['id'] != q['id']:\n",
    "        for j in range(len(answers)):\n",
    "            if answers[j]['id'] == q['id']:\n",
    "                a = answers[j]\n",
    "                break\n",
    "    text_answer = a['content']\n",
    "    key = ''\n",
    "    if 'multihop1' in q['type']:\n",
    "        key = 'multihop_long_answer'\n",
    "    elif 'name' in q['type']:        \n",
    "        key = 'name'\n",
    "    elif 'loc' in q['type']:\n",
    "        key = 'address'\n",
    "    elif 'angle' in q['type']:\n",
    "        key = 'angle_description'\n",
    "    elif 'area' in q['type']:\n",
    "        key = 'area'\n",
    "    elif 'length' in q['type']:\n",
    "        key = 'length'\n",
    "    elif 'count' in q['type']:\n",
    "        key = 'count'\n",
    "    elif 'distance' in q['type']:\n",
    "        key = 'distance'\n",
    "    true_answer = []\n",
    "    for a in q['answers']:\n",
    "        v = evaluate.get_osm_value(a, key)\n",
    "        if v == None:\n",
    "            continue\n",
    "        if key in ['area', 'length', 'count', 'distance']:\n",
    "            v = num2words(v)\n",
    "        if 'area' == key:\n",
    "            v += ' meters squared'\n",
    "        elif key in ['length', 'distance']:\n",
    "            v += ' meters'\n",
    "        true_answer.append(v)\n",
    "    if len(text_answer):\n",
    "        true_answer = '\\n'.join(true_answer)\n",
    "        P, R, F1 = evaluate.evaluate_entity_names(text_answer, true_answer)\n",
    "        text_evaluation.append({'attempted': True, 'P': P, 'R': R, 'F1': F1})\n",
    "    else:\n",
    "        text_evaluation.append({'attempted': False, 'P': 0, 'R': 0, 'F1': 0})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(text_evaluation)\n",
    "df['type'] = [q['type'] for q in questions]\n",
    "df['id'] = [q['id'] for q in questions]\n",
    "df.to_csv(f'./shuffled_text_eval.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800/2800 [00:02<00:00, 1060.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# evaluate parsed_answers\n",
    "parsed_evaluation = []\n",
    "progress = tqdm.tqdm(range(len(questions)))\n",
    "def imporved_f1(new_f1, scores):\n",
    "    return ('F1' not in scores) or (new_f1 > scores['F1'])\n",
    "\n",
    "for i in progress:\n",
    "    q = questions[i]\n",
    "    parsed_answer = parsed_answers[i]\n",
    "    scores = {'attempted': False}\n",
    "    if 'multihop1' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'multihop_answer')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_answer = p.get(a['multihop_attribute'], None)\n",
    "                if pred_answer == None or len(pred_answer) == 0:\n",
    "                    continue\n",
    "                P, R, F1 = evaluate.evaluate_entity_names(pred_answer, v)\n",
    "                if imporved_f1(F1, scores):\n",
    "                    scores = {'attempted': True, 'P': P, 'R': R, 'F1': F1}\n",
    "    elif 'name' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'name')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_answer = p.get('name', None)\n",
    "                if pred_answer == None or len(pred_answer) == 0:\n",
    "                    continue\n",
    "                P, R, F1 = evaluate.evaluate_entity_names(pred_answer, v)\n",
    "                if imporved_f1(F1, scores):\n",
    "                    scores = { 'attempted': True, 'P': P, 'R': R, 'F1': F1}\n",
    "    elif 'loc' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'address')\n",
    "            loc = evaluate.get_osm_value(a, 'location')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_answer = p.get('address', None)\n",
    "                if pred_answer == None or len(pred_answer) == 0:\n",
    "                    continue\n",
    "                if type(pred_answer) == type([]):\n",
    "                    pred_answer = ', '.join(pred_answer)\n",
    "                if type(pred_answer) == dict:\n",
    "                    pred_answer = ', '.join(pred_answer.values())\n",
    "                P, R, F1 = evaluate.evaluate_entity_names(pred_answer, v)\n",
    "                if imporved_f1(F1, scores):\n",
    "                    scores.update({'attempted': True,'P': P, 'R': R, 'F1': F1})\n",
    "                pred_loc = evaluate.get_location_by_address(geocoder, pred_answer)\n",
    "                if pred_loc == None:\n",
    "                    continue\n",
    "                distance_error = evaluate.evaluate_location(geod, [pred_loc], [loc])[0]\n",
    "                distance_limit = 5*10**5\n",
    "                if distance_error > distance_limit:\n",
    "                    distance_error = 1.0\n",
    "                else:\n",
    "                    distance_error /= distance_limit\n",
    "                if distance_error < scores.get('distance_error', float('inf')):\n",
    "                    scores['distance_error'] = distance_error\n",
    "    elif 'angle' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            angle = evaluate.get_osm_value(a, 'angle')\n",
    "            angle_desc = evaluate.get_osm_value(a, 'angle_description')\n",
    "            if angle == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_angle = p.get('azimuth_angle', None)\n",
    "                try:\n",
    "                    pred_angle = int(pred_angle)\n",
    "                except:\n",
    "                    continue\n",
    "                pred_answer = evaluate.get_angle_desc(pred_angle)\n",
    "                if pred_answer == None or len(pred_answer) == 0:\n",
    "                    continue\n",
    "                P, R, F1 = evaluate.evaluate_entity_names(pred_answer, angle_desc)\n",
    "                if imporved_f1(F1, scores):\n",
    "                    scores.update({'attempted': True,'P': P, 'R': R, 'F1': F1})\n",
    "                angle_error = evaluate.evaluate_angle([pred_angle], [angle])[0]\n",
    "                if angle_error < scores.get('angle_error', float('inf')):\n",
    "                    scores['angle_error'] = angle_error\n",
    "    elif 'area' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'area')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_v = p.get('area', None)\n",
    "                if pred_v == None:\n",
    "                    continue\n",
    "                try:\n",
    "                    pred_v = int(pred_v)\n",
    "                except:\n",
    "                    continue\n",
    "                relative_error = evaluate.evaluate_measurement(pred_v, v)\n",
    "                if relative_error < scores.get('relative_error', float('inf')):\n",
    "                    scores['relative_error'] = relative_error\n",
    "                    scores['attempted'] = True\n",
    "    elif 'length' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'length')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_v = p.get('length', None)\n",
    "                if pred_v == None:\n",
    "                    continue\n",
    "                try:\n",
    "                    pred_v = int(pred_v)\n",
    "                except:\n",
    "                    continue\n",
    "                relative_error = evaluate.evaluate_measurement(pred_v, v)\n",
    "                if relative_error < scores.get('relative_error', float('inf')):\n",
    "                    scores['relative_error'] = relative_error\n",
    "                    scores['attempted'] = True\n",
    "    elif 'count' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'count')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_v = p.get('count', None)\n",
    "                if pred_v == None:\n",
    "                    continue\n",
    "                try:\n",
    "                    pred_v = int(pred_v)\n",
    "                except:\n",
    "                    continue\n",
    "                relative_error = evaluate.evaluate_measurement(pred_v, v)\n",
    "                if relative_error < scores.get('relative_error', float('inf')):\n",
    "                    scores['relative_error'] = relative_error\n",
    "                    scores['attempted'] = True\n",
    "    elif 'distance' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'distance')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_v = p.get('distance', None)\n",
    "                if pred_v == None:\n",
    "                    continue\n",
    "                try:\n",
    "                    pred_v = int(pred_v)\n",
    "                except:\n",
    "                    continue\n",
    "                relative_error = evaluate.evaluate_measurement(pred_v, v)\n",
    "                if relative_error < scores.get('relative_error', float('inf')):\n",
    "                    scores['relative_error'] = relative_error\n",
    "                    scores['attempted'] = True\n",
    "    parsed_evaluation.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(parsed_evaluation)\n",
    "df['type'] = [q['type'] for q in questions]\n",
    "df['id'] = [q['id'] for q in questions]\n",
    "df.loc[df['P'].isna(), 'P'] = 0\n",
    "df.loc[df['R'].isna(), 'R'] = 0\n",
    "df.loc[df['F1'].isna(), 'F1'] = 0\n",
    "df.loc[df['distance_error'].isna(), 'distance_error'] = 1.0\n",
    "df.loc[df['angle_error'].isna(), 'angle_error'] = 1.0\n",
    "df.loc[df['relative_error'].isna(), 'relative_error'] = 1.0\n",
    "\n",
    "df.to_csv(f'./shuffled_parsed_eval.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5150408509020873\n"
     ]
    }
   ],
   "source": [
    "# one correct answer vs. one predicted answer\n",
    "simulate_angle_error = [i for i in range(361)]\n",
    "errors = []\n",
    "for a1 in range(100): # a1 is correct answer\n",
    "    a1 = random.choice(range(361))\n",
    "    for _ in range(1): # repetitions for each correct answer\n",
    "        a2 = random_angle()['angle'] #random.choice(range(361))\n",
    "        errors += evaluate.evaluate_angle([a1], [a2])\n",
    "print(np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26577408433364114\n"
     ]
    }
   ],
   "source": [
    "# one correct answer vs. N predicted answers\n",
    "N = 3\n",
    "simulate_angle_error = [i for i in range(361)]\n",
    "errors = []\n",
    "for a1 in range(361): # a1 is correct answer\n",
    "    for _ in range(1): # repetitions for each correct answer\n",
    "        _errors = []\n",
    "        for i in range(N): # generate multiple predictions\n",
    "            a2 = random.choice(range(361)) #random_angle()['angle']\n",
    "            _errors += evaluate.evaluate_angle([a1], [a2])\n",
    "        errors += [min(_errors)]    \n",
    "print(np.mean(errors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
