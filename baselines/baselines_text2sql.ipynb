{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['llama', 'gpt', 'deepseek'][1]\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from glob import glob\n",
    "import json\n",
    "from num2words import num2words\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama = ChatOllama(\n",
    "        model=\"llama3.2\",\n",
    "        temperature=0,\n",
    "        num_ctx=4096,\n",
    "        num_predict=2048,\n",
    "    )\n",
    "model = None\n",
    "if model_name == 'llama':\n",
    "    model = llama\n",
    "else:\n",
    "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "        # base_url=\"...\",\n",
    "        # organization=\"...\",\n",
    "        # other params...\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('./selected_questions/*.jsonl')\n",
    "questions = []\n",
    "for path in files:\n",
    "    question_type = path[path.rfind('/')+1:-6]\n",
    "    with open(path, 'r') as file:\n",
    "        for i in range(100):\n",
    "            line = file.readline()\n",
    "            question = json.loads(line)\n",
    "            question['type'] = question_type\n",
    "            questions.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sql gets the table schema:\n",
    "\"\"\"\n",
    "SELECT column_name, data_type\n",
    "from Information_schema.Columns\n",
    "where table_name = 'lakes';\n",
    "\"\"\"\n",
    "\n",
    "system_prompt1 = str(\n",
    "\"\"\"Convert the provided user question to a SQL query.\n",
    "The following are the tables that exist in the database:\n",
    "\n",
    "Table 1: pois\n",
    "contains the points of interest\n",
    "Schema:\n",
    "   column_name    |     description     \n",
    "------------------+-------------------\n",
    " id               | unique identifier\n",
    " geometry         | geography type represents the shape and position on earth\n",
    " poi_name         | name of the poi\n",
    " wikidata         | unique identifier reference to wikidata\n",
    " wikipedia        | unique name reference to wikipedia page\n",
    " addr_state       | the state where the poi is located\n",
    " addr_city        | the city where the poi is located\n",
    " cuisine          | type of cuisine the associated with restaurant pois\n",
    " leisure          | type of leisure\n",
    " tourism          | type of tourism\n",
    " takeaway         | indicates if a resturant offers takeaway\n",
    " drive_through    | indicates if a resturant offers drive through\n",
    " museum           | type of museum\n",
    " healthcare       | type of healthcare service\n",
    " outdoor_seating  | indicates if an amenity has outdoor seating\n",
    " emergency        | indicates if a healthcare service provides emergency service\n",
    " restaurant       | attribute related to restaurants\n",
    " amenity          | type of amenity provided\n",
    "\n",
    "\n",
    "Table 2: lakes\n",
    "contains lakes, rivers, waterbodies, etc.\n",
    "Schema:\n",
    "   column_name    |     description     \n",
    "------------------+-------------------\n",
    " id               | unique identifier\n",
    " geometry         | geography type represents the shape and position on earth\n",
    " lake_name        | name of the lake\n",
    " wikidata         | unique identifier reference to wikidata\n",
    " wikipedia        | unique name reference to wikipedia page\n",
    " addr_country     | the country where the lake is located\n",
    " addr_state       | the state where the lake is located\n",
    " addr_county      | the county where the lake is located\n",
    " addr_city        | the city where the lake is located\n",
    " addr_postcode    | postcode where the lake is located\n",
    " addr_street      | street where the lake is located\n",
    " addr_housenumber | house number specific to this lake\n",
    " waterway         | type of waterway\n",
    " water            | type of waterbody\n",
    "\n",
    "Table 3: parks\n",
    "contains parks, gardens, etc.\n",
    "Schema:\n",
    "   column_name    |     description     \n",
    "------------------+-------------------\n",
    " id               | unique identifier\n",
    " geometry         | geography type represents the shape and position on earth\n",
    " park_name        | name of the park\n",
    " wikidata         | unique identifier reference to wikidata\n",
    " wikipedia        | unique name reference to wikipedia page\n",
    " leisure          | type of leisure\n",
    " park             | type of park\n",
    " tourism          | type of tourism\n",
    "\n",
    "Table 4: roads\n",
    "contains roads, walkways, etc.\n",
    "Schema:\n",
    "   column_name    |     description     \n",
    "------------------+-------------------\n",
    " id               | unique identifier\n",
    " geometry         | geography type represents the shape and position on earth\n",
    " road_name        | name of the road\n",
    " wikidata         | unique identifier reference to wikidata\n",
    " wikipedia        | unique name reference to wikipedia page\n",
    " highway          | attribute associated with roads of type highway\n",
    " sidewalk         | attribute associated with roads of type sidewalk\n",
    " foot             | attribute associated with roads of type foot\n",
    " bicycle          | attribute associated with roads of type bycycle\n",
    " cycleway         | attribute associated with roads of type cycleway\n",
    "\n",
    "Table 5: regions\n",
    "contains adminstrative region boundaries, like cities and states, etc.\n",
    "Schema:\n",
    "  column_name  |     data_type     \n",
    "---------------+-------------------\n",
    " id            | integer\n",
    " geometry         | geography type represents the shape and position on earth\n",
    " region_name   | name of the region\n",
    " border_type   | the type of border\n",
    " wikidata      | unique identifier reference to wikidata\n",
    " wikipedia     | unique name reference to wikipedia page\n",
    "\n",
    "When creating the sql queries make sure of the following:\n",
    "- they match the table names provided\n",
    "- the columns must exist in the provided table schema\n",
    "- the queries are compatible with PostGIS.\n",
    "- make sure to cast the geography columns to geometry if needed\n",
    "- do not include the geometry column or location in the output\n",
    "- string matching must be flexible, use ILIKE and the '%' sign.\n",
    "- do not include any description or text, just the sql query.\n",
    "- the query starts with ```sql and ends with ```\n",
    "Note all tables are based on OpenStreetMap data.\n",
    "\"\"\"\n",
    ") # TODO: possibly add instruction to limit the outputs records\n",
    "\n",
    "system_prompt2 = str(\"Answer the provided user question while satisfying the following requirements:\\n\"\n",
    "                    \"1. do not include any parts of the question in the answer you must provide the answer directly.\\n\"\n",
    "                    \"2. provide only the property the user is asking for like name of an entity, its location, distance, direction.\\n\"\n",
    "                    \"3. don't provide information the user didn't ask for.\\n\"\n",
    "                    \"4. any number must be written as words and rounded to the nearest ten.\\n\"\n",
    "                    \"5. only use metric units.\\n\\n\"\n",
    "                    \"The following records might be relavant to answering this question:\\n\")\n",
    "\n",
    "\n",
    "system_prompt3 = str(\"Given a question and a text answer, parse the text answer to json format.\"\n",
    "                     \" The location must be provided as a complete address,\"\n",
    "                     \" any measurment must be in metric units,\"\n",
    "                     \" and directions must be converted to azimuth angle in degress.\"\n",
    "                     \" Try to match the following schema:\"\n",
    "                     \"\"\"\n",
    "                        {\n",
    "                            \"name\" string\n",
    "                            \"address\": string,\n",
    "                            \"count\": integer,\n",
    "                            \"distance\": integer,\n",
    "                            \"length\": integer,\n",
    "                            \"area\": integer,\n",
    "                            \"azimuth_angle\": integer,\n",
    "                            %OTHER_ATT%\n",
    "                        }\n",
    "                    If a value is missing don't include it in the output, and don't write any comments.\n",
    "                    All json blocks must be enclosed with ```json and ```\n",
    "                     \"\"\")\n",
    "\n",
    "# You can use the following examples as a guide:\n",
    "# Example 1: What is the largest park in Tuscon, Arizona?\n",
    "# ```sql\n",
    "# SELECT *, ST_Area(parks.geometry::geography) AS computed_area FROM parks\\nWHERE leisure = 'park'\\nAND ST_Intersects(parks.geometry::geography, (SELECT geometry FROM regions WHERE wikipedia = `en:Tucson, Arizona` LIMIT 1)::geography) ORDER BY computed_area DESC LIMIT 1;\n",
    "# ```\n",
    "# Example 2: \n",
    "# What is the total area of all gardens in Riverside, California?\n",
    "# ```sql\n",
    "# SELECT SUM(ST_Area(parks.geometry::geography)) AS area FROM parks\\nWHERE leisure = 'garden'\\nAND ST_Intersects(parks.geometry::geography, (SELECT geometry FROM regions WHERE wikipedia = `en:Riverside, California` LIMIT 1)::geography)\n",
    "# ```\n",
    "# \"\"\"\n",
    "#)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "def safe_invoke(messages, timeout=30):\n",
    "    import signal\n",
    "\n",
    "    def handler(signum, frame):\n",
    "        raise Exception(\"Request timed out\")\n",
    "\n",
    "    signal.signal(signal.SIGALRM, handler)\n",
    "    signal.alarm(timeout)\n",
    "\n",
    "    try:\n",
    "        result = model.invoke(messages)\n",
    "        signal.alarm(0)  # Disable alarm\n",
    "        return result\n",
    "    except Exception:\n",
    "        EmptyClass = type('EmptyClass', (), {'content': ''})\n",
    "        # print(\"The request timed out.\")\n",
    "        return EmptyClass()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./text2sql_output_%s.json' % model_name, 'r') as file:\n",
    "    _text2sql_answers = {a['id']: a for a in json.loads(file.read())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800/2800 [00:00<00:00, 1867989.69it/s]\n"
     ]
    }
   ],
   "source": [
    "progress = tqdm.tqdm(questions)\n",
    "\n",
    "text2sql_answers = []\n",
    "for q in progress:\n",
    "    # if q['id'] in processed_q:\n",
    "    #     continue\n",
    "    if q['id'] not in _text2sql_answers:\n",
    "        messages = [\n",
    "                SystemMessage(content=system_prompt1),\n",
    "                HumanMessage(content=q['question'])\n",
    "            ]\n",
    "        text2sql_answers.append({'content': safe_invoke(messages).content, 'id': q['id']})\n",
    "    else:\n",
    "        text2sql_answers.append(_text2sql_answers[q['id']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./text2sql_output_%s.json' % model_name, 'w') as file:\n",
    "    file.write(json.dumps(text2sql_answers, indent=2))\n",
    "with open('./text2sql_output_%s.json' % model_name, 'r') as file:\n",
    "    text2sql_answers = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def flatten_if_nested(array):\n",
    "    # Check if the input is a list and contains nested lists\n",
    "    if isinstance(array, list) and any(isinstance(item, list) for item in array):\n",
    "        flattened = []\n",
    "        for item in array:\n",
    "            if isinstance(item, list):\n",
    "                flattened.extend(flatten_if_nested(item))\n",
    "            else:\n",
    "                flattened.append(item)\n",
    "        return flattened\n",
    "    else:\n",
    "        return array  # Return the input as-is if it's not a list or doesn't contain nested lists\n",
    "\n",
    "def extract_json_blocks(text, i):\n",
    "    # Regular expression pattern to match JSON blocks\n",
    "    pattern = r'```[\\s]*json(.*?)```'\n",
    "    pattern1 = r'\\b\\d+(?:_\\d+)*\\b'\n",
    "    pattern2 = r'\\b\\d+(?:,\\d+)*\\b'\n",
    "    pattern3 = r'//.*?\\n'\n",
    "    pattern4 = r',\\s*}'\n",
    "    pattern5 = r'}\\s*{'\n",
    "    # Find all JSON blocks\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    # Parse each match to ensure valid JSON\n",
    "    json_blocks = []\n",
    "    for match in matches:\n",
    "        try:\n",
    "            # Remove any leading/trailing whitespace and parse as JSON\n",
    "            s = match.strip()\n",
    "            s = re.sub(pattern1, lambda x: x.group().replace('_', ''), s)\n",
    "            s = re.sub(pattern2, lambda x: x.group().replace(',', ''), s)\n",
    "            s = re.sub(pattern3, '', s)\n",
    "            s = re.sub(pattern4, '}', s)\n",
    "            s = s.replace('''\\\\\\\\\\'''',  '''\\'''').replace('''\\\\\\'''', '''\\'''').replace('''\\\\&''', '''&''')\n",
    "            if re.search(pattern5, s):\n",
    "                s = re.sub(pattern5, '},\\n{', s)\n",
    "                s = '[\\n%s\\n]' % s\n",
    "            convert_area = False\n",
    "            if 'acres' in s:\n",
    "                convert_area = True\n",
    "                s = s.replace(' acres,', ',')\n",
    "            if 'json' in s:\n",
    "                s = s.replace('json', '')\n",
    "            # print(s)\n",
    "            json_data = json.loads(s)\n",
    "            if convert_area and 'area' in json_data:\n",
    "                json_data['area'] = json_data['area'] * 4046.8564224\n",
    "            json_blocks.append(json_data)\n",
    "        except json.JSONDecodeError as w:\n",
    "            print(w)\n",
    "            # If parsing fails, print an error message (can log or handle as needed)\n",
    "            print(i)\n",
    "            print(s)\n",
    "            print(\"Warning: Found an invalid JSON block.\") \n",
    "    return flatten_if_nested(json_blocks)\n",
    "\n",
    "def extract_sql_blocks(text):\n",
    "    # Regular expression pattern to match SQL blocks\n",
    "    pattern = r'```[\\s]*sql(.*?)```'\n",
    "    # Find all SQL blocks\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    sql_blocks = []\n",
    "    for match in matches:\n",
    "        sql_blocks.append(match)\n",
    "    # if not len(sql_blocks):\n",
    "    #     pattern = r'```(.*?)```'\n",
    "    #     matches = re.findall(pattern, text, re.DOTALL)\n",
    "    #     for match in matches:\n",
    "    #         # possibly some processing here\n",
    "    #         sql_blocks.append(match)\n",
    "    return sql_blocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from psycopg.rows import dict_row\n",
    "\n",
    "def run_sql(sql, conn, timeout):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SET statement_timeout = %d\" % timeout)\n",
    "    try:\n",
    "        cur.execute(sql)\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        return {'output': [], 'error': str(e)}\n",
    "    records = cur.fetchmany(size=100)\n",
    "    cur.close()\n",
    "    return {'output': [{k: row[k] for k in row if row[k] is not None} for row in records], 'error': ''}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_time = pd.read_csv('./sql_answers_time.csv').groupby('type')['time'].max().to_dict()\n",
    "sql_time = {k: max(int(sql_time[k])*2, 10) for k in sql_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./sql_outputs_%s.json' % model_name, 'r') as file:\n",
    "    _sql_output = {a['id']: a for a in json.loads(file.read())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800/2800 [00:00<00:00, 1029096.67it/s]\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg.connect(\n",
    "    host = 'localhost',\n",
    "    dbname = 'osm_ca',\n",
    "    user = 'postgres',\n",
    "    password = 'postgres',\n",
    "    port = 5432,\n",
    "    row_factory=dict_row,\n",
    "    # options=\"-c statement_timeout=180000\"\n",
    ")\n",
    "\n",
    "\n",
    "sql_output = []\n",
    "progress = tqdm.tqdm(range(len(text2sql_answers)))\n",
    "for i in progress:\n",
    "    q = questions[i]\n",
    "    if q['id'] not in _sql_output:\n",
    "        a = text2sql_answers[i]\n",
    "        if a['id'] != q['id']:\n",
    "            for j in range(len(text2sql_answers)):\n",
    "                if text2sql_answers[j]['id'] == q['id']:\n",
    "                    a = text2sql_answers[j]\n",
    "                    break\n",
    "        sql_blocks = extract_sql_blocks(a['content'])\n",
    "        records = []\n",
    "        for sql in sql_blocks:\n",
    "            records.append(run_sql(sql, conn, sql_time[q['type']]))\n",
    "        sql_output.append({'id': q['id'], 'records': records})\n",
    "    else:\n",
    "        sql_output.append(_sql_output[q['id']])\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./sql_outputs_%s.json' % model_name, 'w') as file:\n",
    "    file.write(json.dumps(sql_output, indent=2))\n",
    "with open('./sql_outputs_%s.json' % model_name, 'r') as file:\n",
    "    sql_output = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./text2sql_answers_%s.json' % model_name, 'r') as file:\n",
    "    _answers = {a['id']: a for a in json.loads(file.read())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800/2800 [00:00<00:00, 1096857.31it/s]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "progress = tqdm.tqdm(range(len(questions)))\n",
    "for i in progress:\n",
    "    q = questions[i]\n",
    "    if q['id'] not in _answers:\n",
    "        _sql_output = sql_output[i]\n",
    "        if q['id'] != _sql_output['id']:\n",
    "            for j in range(len(sql_output)):\n",
    "                _sql_output = sql_output[j]\n",
    "                if q['id'] == _sql_output['id']:\n",
    "                    break\n",
    "        sql_context = []\n",
    "        for c in _sql_output['records']:\n",
    "            sql_context += [str(r) for r in c['output']]\n",
    "        if len(sql_context) == 0:\n",
    "            sql_context = []\n",
    "        #elif len(sql_context) > 20:\n",
    "        sql_context = sql_context[:min(len(sql_context), 20)]\n",
    "        messages = [\n",
    "                SystemMessage(content= system_prompt2 + '\\n'.join(sql_context)),\n",
    "                HumanMessage(content=q['question'])\n",
    "            ]\n",
    "        answers.append({'id':q['id'], 'content': model.invoke(messages).content})\n",
    "    else:\n",
    "        answers.append(_answers[q['id']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./text2sql_answers_%s.json' % model_name, 'w') as file:\n",
    "#     file.write(json.dumps(answers, indent=2))\n",
    "with open('./text2sql_answers_%s.json' % model_name, 'r') as file:\n",
    "    answers = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./text2sql_json_answers_%s.json' % model_name, 'r') as file:\n",
    "        _json_answers = {a['id']: a for a in json.loads(file.read())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_answers = []\n",
    "for i in range(len(questions)):\n",
    "    q = questions[i]\n",
    "    if q['id'] not in _json_answers:\n",
    "        if 'multihop1' in q['type']:\n",
    "            sys_prompt= system_prompt3.replace('%OTHER_ATT%', '\"%s\": string' % q['answers'][0]['multihop_attribute'])\n",
    "        else:\n",
    "            sys_prompt= system_prompt3.replace('%OTHER_ATT%', '')\n",
    "        a = answers[i]\n",
    "        if a['id'] != q['id']:\n",
    "            for j in range(len(answers)):\n",
    "                if answers[j]['id'] == q['id']:\n",
    "                    a = answers[j]\n",
    "                    break\n",
    "        messages = [\n",
    "                SystemMessage(content=sys_prompt),\n",
    "                HumanMessage(content=\"Question: %s\\nAnswer: %s\" % (q['question'], a['content']))\n",
    "            ]\n",
    "        json_answers.append({'id':q['id'], 'content': llama.invoke(messages).content})\n",
    "    else:\n",
    "        json_answers.append(_json_answers[q['id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./text2sql_json_answers_%s.json' % model_name, 'w') as file:\n",
    "#         file.write(json.dumps(json_answers, indent=2))\n",
    "with open('./text2sql_json_answers_%s.json' % model_name, 'r') as file:\n",
    "        json_answers = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_answers = []\n",
    "for i in range(len(json_answers)):\n",
    "    q = questions[i]\n",
    "    a = json_answers[i]\n",
    "    if a['id'] != q['id']:\n",
    "        for j in range(len(json_answers)):\n",
    "            if json_answers[j]['id'] == q['id']:\n",
    "                a = json_answers[j]\n",
    "                break\n",
    "    parsed_answers.append(extract_json_blocks(a['content'], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Mediterranean restaurant',\n",
       "  'address': 'Bowling Green, Kentucky',\n",
       "  'distance': None,\n",
       "  'length': None,\n",
       "  'area': None,\n",
       "  'azimuth_angle': None}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from pyproj import Geod\n",
    "\n",
    "geod = Geod(ellps='WGS84')\n",
    "geocoder = Nominatim(user_agent=\"Geocoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/majid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/majid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/majid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/majid/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import evaluate\n",
    "importlib.reload(evaluate)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_evaluation = []\n",
    "\n",
    "# evaluate text answers\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    q = questions[i]\n",
    "    a = answers[i]\n",
    "    if a['id'] != q['id']:\n",
    "        for j in range(len(answers)):\n",
    "            if answers[j]['id'] == q['id']:\n",
    "                a = answers[j]\n",
    "                break\n",
    "    text_answer = a['content']\n",
    "    key = ''\n",
    "    if 'multihop1' in q['type']:\n",
    "        key = 'multihop_long_answer'\n",
    "    elif 'name' in q['type']:        \n",
    "        key = 'name'\n",
    "    elif 'loc' in q['type']:\n",
    "        key = 'address'\n",
    "    elif 'angle' in q['type']:\n",
    "        key = 'angle_description'\n",
    "    elif 'area' in q['type']:\n",
    "        key = 'area'\n",
    "    elif 'length' in q['type']:\n",
    "        key = 'length'\n",
    "    elif 'count' in q['type']:\n",
    "        key = 'count'\n",
    "    elif 'distance' in q['type']:\n",
    "        key = 'distance'\n",
    "    true_answer = []\n",
    "    for a in q['answers']:\n",
    "        v = evaluate.get_osm_value(a, key)\n",
    "        if v == None:\n",
    "            continue\n",
    "        if key in ['area', 'length', 'count', 'distance']:\n",
    "            v = num2words(v)\n",
    "        if 'area' == key:\n",
    "            v += ' meters squared'\n",
    "        elif key in ['length', 'distance']:\n",
    "            v += ' meters'\n",
    "        true_answer.append(v)\n",
    "    if len(text_answer):\n",
    "        true_answer = '\\n'.join(true_answer)\n",
    "        P, R, F1 = evaluate.evaluate_entity_names(text_answer, true_answer)\n",
    "        text_evaluation.append({'attempted': True, 'P': P, 'R': R, 'F1': F1})\n",
    "    else:\n",
    "        text_evaluation.append({'attempted': False, 'P': 0, 'R': 0, 'F1': 0})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(text_evaluation)\n",
    "df['type'] = [q['type'] for q in questions]\n",
    "df['id'] = [q['id'] for q in questions]\n",
    "df.to_csv(f'./{model_name}_text2sql_text_eval.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recursive(data, search_key):\n",
    "    outputs = []\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if key == search_key and isinstance(value, str):  # Check for key and if the value is a string\n",
    "                outputs.append(value)\n",
    "            else:\n",
    "                outputs.extend(get_recursive(value, search_key))  # Recurse for nested structures\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            outputs.extend(get_recursive(item, search_key))  # Recurse for list elements\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800/2800 [00:02<00:00, 1094.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# evaluate parsed_answers\n",
    "parsed_evaluation = []\n",
    "progress = tqdm.tqdm(range(len(questions)))\n",
    "def imporved_f1(new_f1, scores):\n",
    "    return ('F1' not in scores) or (new_f1 > scores['F1'])\n",
    "\n",
    "for i in progress:\n",
    "    q = questions[i]\n",
    "    parsed_answer = parsed_answers[i]\n",
    "    scores = {'attempted': False}\n",
    "    if 'multihop1' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'multihop_answer')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_answer = p.get(a['multihop_attribute'], None)\n",
    "                if pred_answer == None or len(pred_answer) == 0:\n",
    "                    continue\n",
    "                P, R, F1 = evaluate.evaluate_entity_names(pred_answer, v)\n",
    "                if imporved_f1(F1, scores):\n",
    "                    scores = {'attempted': True, 'P': P, 'R': R, 'F1': F1}\n",
    "    elif 'name' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'name')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                # pred_answer = p.get('name', None)\n",
    "                pred_answer = get_recursive(p, 'name')\n",
    "                if pred_answer == None or len(pred_answer) == 0:\n",
    "                    continue\n",
    "                pred_answer = pred_answer[0]\n",
    "                P, R, F1 = evaluate.evaluate_entity_names(pred_answer, v)\n",
    "                if imporved_f1(F1, scores):\n",
    "                    scores = { 'attempted': True, 'P': P, 'R': R, 'F1': F1}\n",
    "    elif 'loc' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'address')\n",
    "            loc = evaluate.get_osm_value(a, 'location')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                # pred_answer = p.get('address', None)\n",
    "                pred_answer = get_recursive(p, 'address')\n",
    "                if pred_answer == None or len(pred_answer) == 0:\n",
    "                    continue\n",
    "                pred_answer = pred_answer[0]\n",
    "                # if type(pred_answer) == type([]):\n",
    "                #     pred_answer = ', '.join(pred_answer)\n",
    "                P, R, F1 = evaluate.evaluate_entity_names(pred_answer, v)\n",
    "                if imporved_f1(F1, scores):\n",
    "                    scores.update({'attempted': True,'P': P, 'R': R, 'F1': F1})\n",
    "                pred_loc = evaluate.get_location_by_address(geocoder, pred_answer)\n",
    "                if pred_loc == None:\n",
    "                    continue\n",
    "                distance_error = evaluate.evaluate_location(geod, [pred_loc], [loc])[0]\n",
    "                if distance_error > 5*10**5:\n",
    "                    distance_error = 1.0 #float('inf')\n",
    "                else:\n",
    "                    distance_error /= 5*10**5\n",
    "                if distance_error < scores.get('distance_error', float('inf')):\n",
    "                    scores['distance_error'] = distance_error\n",
    "    elif 'angle' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            angle = evaluate.get_osm_value(a, 'angle')\n",
    "            angle_desc = evaluate.get_osm_value(a, 'angle_description')\n",
    "            if angle == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_angle = p.get('azimuth_angle', None)\n",
    "                try:\n",
    "                    pred_angle = int(pred_angle)\n",
    "                except:\n",
    "                    continue\n",
    "                pred_answer = evaluate.get_angle_desc(pred_angle)\n",
    "                if pred_answer == None or len(pred_answer) == 0:\n",
    "                    continue\n",
    "                P, R, F1 = evaluate.evaluate_entity_names(pred_answer, angle_desc)\n",
    "                if imporved_f1(F1, scores):\n",
    "                    scores.update({'attempted': True,'P': P, 'R': R, 'F1': F1})\n",
    "                angle_error = evaluate.evaluate_angle([pred_angle], [angle])[0]\n",
    "                if angle_error < scores.get('angle_error', float('inf')):\n",
    "                    scores['angle_error'] = angle_error\n",
    "    elif 'area' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'area')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_v = p.get('area', None)\n",
    "                if pred_v == None:\n",
    "                    continue\n",
    "                try:\n",
    "                    pred_v = int(pred_v)\n",
    "                except:\n",
    "                    continue\n",
    "                relative_error = evaluate.evaluate_measurement(pred_v, v)\n",
    "                if relative_error < scores.get('relative_error', float('inf')):\n",
    "                    scores['relative_error'] = relative_error\n",
    "                    scores['attempted'] = True\n",
    "    elif 'length' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'length')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_v = p.get('length', None)\n",
    "                if pred_v == None:\n",
    "                    continue\n",
    "                try:\n",
    "                    pred_v = int(pred_v)\n",
    "                except:\n",
    "                    continue\n",
    "                relative_error = evaluate.evaluate_measurement(pred_v, v)\n",
    "                if relative_error < scores.get('relative_error', float('inf')):\n",
    "                    scores['relative_error'] = relative_error\n",
    "                    scores['attempted'] = True\n",
    "    elif 'count' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'count')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_v = p.get('count', None)\n",
    "                if pred_v == None:\n",
    "                    continue\n",
    "                try:\n",
    "                    pred_v = int(pred_v)\n",
    "                except:\n",
    "                    continue\n",
    "                relative_error = evaluate.evaluate_measurement(pred_v, v)\n",
    "                if relative_error < scores.get('relative_error', float('inf')):\n",
    "                    scores['relative_error'] = relative_error\n",
    "                    scores['attempted'] = True\n",
    "    elif 'distance' in q['type']:\n",
    "        for a in q['answers']:\n",
    "            v = evaluate.get_osm_value(a, 'distance')\n",
    "            if v == None:\n",
    "                continue\n",
    "            for p in parsed_answer:\n",
    "                pred_v = p.get('distance', None)\n",
    "                if pred_v == None:\n",
    "                    continue\n",
    "                try:\n",
    "                    pred_v = int(pred_v)\n",
    "                except:\n",
    "                    continue\n",
    "                relative_error = evaluate.evaluate_measurement(pred_v, v)\n",
    "                if relative_error < scores.get('relative_error', float('inf')):\n",
    "                    scores['relative_error'] = relative_error\n",
    "                    scores['attempted'] = True\n",
    "    parsed_evaluation.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(parsed_evaluation)\n",
    "df['type'] = [q['type'] for q in questions]\n",
    "df['id'] = [q['id'] for q in questions]\n",
    "df.loc[df['P'].isna(), 'P'] = 0\n",
    "df.loc[df['R'].isna(), 'R'] = 0\n",
    "df.loc[df['F1'].isna(), 'F1'] = 0\n",
    "df.loc[df['distance_error'].isna(), 'distance_error'] = 1.0\n",
    "df.loc[df['angle_error'].isna(), 'angle_error'] = 1.0\n",
    "df.loc[df['relative_error'].isna(), 'relative_error'] = 1.0\n",
    "\n",
    "df.to_csv(f'./{model_name}_text2sql_parsed_eval.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
